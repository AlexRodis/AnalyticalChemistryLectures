# Στατιστική Επεξεργασία Αποτελσμάτων

## Σφάλματα

Τα πειραματικά σφάλματα χωρίζονται σε διάφορες κατηγορίες. Οι δύο κυριότερες είναι *τυχαία* και *συστηματικά*.

>**Συστηματικά** ή καθορισμένα σφάλματα ονομάζονται αυτά που οφείλονται σε έναν ή περισσότερους λόγος προσδιορίσημης αν όχι γνωστής προέλευσης.

>**Τυχαία** ή  και ακαθόριστα ονομάζονται τα σφάλματα που οφείλονται σε ακαθόριστα αίτα και είναι ουσιαστικά στατιστηκός "θόρυβος" που πάντα υπάρχει σε κάποιο βαθμό.

>**Ολικό** σφάλμα είναι το άθροισμα όλων των επιμέρους σφαλμάτων δηλαδή στατιστικών και συστηματικών. Αναφέρεται και ως *μικτό*.

>**Μονοκατευθυνόμενα** είναι τα σφάλματα που εμφανίζουν συστηματικό πρόσυμο. Μπορεί και είναι μονοκατευθυνόμενο εντός μικρότερων υπο περιοχών. Είναι γενικά συστηματικά.

>**Απόλυτο** ονομάζεται η διαφορά της "πραγματικής" από την πειραματική τιμή. Μπορεί να εξαρτάται από τη συγκέντρωση ή όχι.

>**Σχετικό** ονομάζεται το σφάλμα αναγόμενο στο μέγεθος (απόλυτο ανά μέγεθως).

Μπορούμε να διερευνήσουμε τη σφάλματα με απλά διαγράμματα συσχέτησης πειραματικής τιμής έναντι πραγματικής. Γενικά μιά έλλειψη τυχαιότητας στο πρόσημο δηλώνει συστηματικό σφάλμα.

![correlation plots]()

Γενικά ή ύπαρξη *τάσης* (ή *ολίσθησης*) των τιμών (είτε ανοδικής είτε καθοδικής) δείχνει οτι η μητριτική διαδικάσία είναι εκτός ελέγχου και η μέση τιμή είναι στατιστικά άχρηστη. Αυστηρότερα προσδιορίζεται ως εξής. Λαμβάνουμε τις επαναλαμβανόμενες τιμές και προσαρμόζουμε ένα γραμμικό μοντέλο:

$$
Y=w_0N+w_1\\
$$

Τότε αν η κλίση είναι στατιστικά σημαντική $w_0\ne 0 \pm s_{w_0}$ τότε υπάρχει ολίσθηση. Μια απλή περιγραφή των σφαλμάτων είναι:

$$
x_i=\mu+ b+ e
$$
Για μία μέτρηση. Όπου $b$ είναι το συστηματικό και $e$ το τυχαίο σφάλμα. Αντίστοιχα, για πολλαπλές μετρήσεις:

$$
x_i=\mu+(\bar{x}-\mu)+(x_i-\mu)
$$

Μπορούμε να αποικονήσουμε τις τιμές ως μια *κατανομή* σε ένα *ιστόγραμμα*, δηλαδή μια απεικόνηση ευρών τιμών (bin) για συνεχείς μεταβλητές ή μεμονομένων τιμών για διακριτές μεταβλητές. Ο μέγιστος επιθυμητός αριθμός *κλάσσεων* ή εύρος ανά κλάσση δίνεται από τον *κανόνα Sturges*

>**Κανόνας Sturges:** $k = 1+3.322\log_{10}{N}$

Στη πράξη, ο αριθμός προσαρμώζεται πάνω ή κάτω ώστε να είναι ποιό στρογγυλά τα εύροι. Μια εναλλακτική παρουσίαση της κατανομής είναι μέσω της *συσσωρευτικής συνάρτησης κατανομής*. Σε αυτή τη περίπτωση σε κάθε κλάση προστίθενται οι παρατηρίσεις των προηγούμενων.

Αριθμητική περιγραφή των πληθυσμών είναι οι παράμετροι *θέσης* ,*διασποράς* και *συμμετρίας*.

## Παράμετροι Θέσης

Οι παράμετροι θέσης πληθυσμού είναι:

* Μέση τιμή $\bar x =\frac{\sum{x_i}}{N}\;\;\; \bar x \rightarrow \mu, n \rightarrow \infty $
* Διάμεση Τιμή $x_{ \frac {n+1}{2} } n:\;\;\;περιττός\;\;\; \frac {x_{ \frac{n}{2} } + x_{\frac {n}{2}} +1 }{2}$
* Ρυθμισμένη Μέση Τιμή
* Επικρατούσα Τιμή
  
## Παράμετροι Διασποράς

Οι βασικές παράμετροι διασποράς είναι:

* Εύρος: $R=x_n-x_1$
* Τυπική Απόκλιση: $s=\sqrt{\frac {\sum_{i=1}^N{(\bar {x}-x_1)^2 }}{N-1} }$, ισχύει ότι $s \rightarrow\sigma, n\rightarrow\infty$
* Σχετική Τυπική Απόκλιση: $s_t=^{s}/_{\bar{x} }$
* Εκατοστιαία Τυπική Απόκλιση: $\%RSD \equiv\%CV=\frac {s}{\bar {x}}*100\%$
* Διακύμανση: $\nu\equiv Var\;\;\; s^2, \sigma^2$
* Μέση Απόλυτη Απόκλιση: $amd=\frac {\sum_{i=1}^N{|{\bar{x}-x_i|}}}{N}$
* Τυπικό Σφάλμα: $SE=\sqrt{\frac {\sum_{i=1}^N{(x_i-\bar{x})}}{N(N-1)}}$
* Εύρος Μεταξύ Ποσοστημοριακών Σημείων
  
## Παράμετροι Συμμετρίας

Οι παράμετροι συμμετρίας είναι μόνο δύο και μετράνε ουσιαστικά το ίδιο πράγμα:

* Ασυμμετρία: $g_i=\frac{\sum_{i=1}^{N}{(x_1-\bar{x})^3}}{(N-1)(N-2)s^3}$
* Κύρτωση: $g_2=\frac 1n \sum_{i=1}^N[\frac {x_i-\bar{x}}{s}]^4-4$
  
## Κανονική Ή Gaussιανή Κατανομή

Η κατανομή Gauss είναι πανταχώς παρούσα στη φύση. Αυτό οφείλεται στο *Κεντρικό Οριακό Θεώρημα*. Θα δούμε μια απλοϊκή διατύπωση γιατί η μαθηματική απόδηξη του είναι εξαιρετικά πολύπλοκη.

>**Κεντρικό Οριακό Θεώρημα:**\
>*Το άθροισμα τιμών προερχόμενων από έναν ή περισσότερους πληθυσμούς με οποιαδήποτε αρχική κατανομή, τείνει να αποτελέσει στοιχείο πληθυσμού με κανονική κατανομή,όσο αυξήνει ο αριθμός των αθροιζόμενων τιμών.*

Δηλαδή, απλοίκά μιλώντας αν $Α$ κάποια αυθέρετη κατανομή τότε:
$$
Α\rightarrow N(\sigma,\mu)
$$

Όπως είδαμε μπορούμε να επικονήσουμε την *κατανομή* ενός πληθυσμού, με ένα ιστόγραμμα είτε χρησιμοποιώντας την συχνότητα είτε την cdf (*cummulative density function*). Θέλουμε από μια κατανομή που αντιπροσωπεύει ένα συγκεκριμένο πλυθησμό, να καταλήξουμε σε κάποιον "παγκόσμιο" τρόπο κατανομής.

>**Παρατήρηση:**\
>Υπάρχουν γενικά, διάφορες κατανομές, όπως Διωνυμική, Bernoulli κλπ. Συνήθως μια τέτοια κατανομή είναι μια γενική περιγραφή ενός *τύπου* κατανομής. Μια συγκεκριμένη μορφή της κάθε κατανομής προσδιορίζεται από (i) την γενική μορφή στην οποία συμμοφώνεται (πχ Διωνυμική,Gauss), και (ii) ένα σύνολο παραμέτρων που δίνουν την ακριβή μορφή. Αυτές οι παράμετροι διαφέρουν για κάθε τύπο κατανομής. Για την Guass οι δύο αυτές παράμετροι είναι η τυπική απόκλιση (*σ*) και το μέσο (*μ*). Η Διωνυμική έχει ένα παράγωντα που ονομάζεται (*p*). Έτσι θα συμβολίζουμε γενικά
>$$
Χ(e_1,e_2,[\dots], e_n)
$$
>και θα εννούμε μια κατανομή γενικού τύπου ($X$) με παραμέτρους $e_1,e_2,\dots, e_n$. Με αυτή τη σύμβαση, θα γράφουμε
>$$
N(\mu,\sigma)
$$
>και θα εννοούμε κατανομή Gauss με μέση τιμή $\mu$ και τυπική απόκλιση $\sigma$.

Η κατανομή Gauss δίνεται από την συνάρτηση κατνανομής $f$ που δίνει τη συχνότητα συναρτήση της παραμέτρου $χ$ και έχει ως εξής:

$$
f(x) = \frac {1}{\sigma \sqrt{2\pi} }e^{=\frac {(x-\mu)^2}{2{\sigma}^2} }
$$

![κατανομή Gauss βασική]()

Μια άλλη ενδιαφέρουσα μορφή της συνάρτησης προκύπτει θέτοντας απλά $z=\frac {x-\mu}{\sigma}$. Τότε η συνάρτηση γίνεται:

$$
f(x) = \frac{1}{\sqrt{2\pi}}\int_{t=-z}^{t=+z}{e^{-t^2}dt}
$$
Αυτή η απεικόνηση δίνετ τη συχνότητα συναρτίση του αριθμού τυπικών αποκλίσεων. Οι τιμές του ολοκληρώματος μπορούν να προκύψουν από πίνακες ή με αριθμητικές μεθόδους (*βλ. SciPy.special.erf,  SciPY.stats.multivariate_normal,  SciPy.stats.norm*).

![μηχανη πληθυσμου Gauss]()

### Το Νόημα των Κρίσιμων Τιμών

Έστω $X(x_1,x_2,x_3,[\dots],x_N)$ με ${x_1,x_2,x_3,[\dots],x_N}$ ν τυχαία επιλεγμένα στοιχεία κανονικού πληθυσμού $Χ$. Για κάθε Ν-άδα υπολογίζεται μια τιμή στατιστικού στοιχείου πληθυσμού $R$ από πληθυσμό $**R**$. Όλοι οι "σχηματισμοί" των τιμών χ προέρχονται από τον ίδιο πληθυσμό και επομένως ισχύει γι αυτούς η μηδενική υπόθεση. Συμβαίνει κάποιοι "ακραίοι" σχηματισμοί Ν στοιχείων να οδηγούν σε "ακραίες" τιμές στατιστικού στοιχείου. Γι αυτούς η μηδενική υπόθεση απορρίπτεται λανθασμένα.

## Κατανομή Μέσω Τιμών

$$
\sigma_{\bar{x}} = \frac {\sigma_x}{\sqrt{N}}
$$

## Στατιστικές Δοκιμασίες Σημαντικότητας

Στις δοκιμασίες σημαντικότητας γνεικά, ξεκινάμε με μια αρχική υπόθεση $Η_0$ που ονομάζεται *μηδενική υπόθεση*, και εκτελούμε μια στατιστική δοκιμασία. Η δοκιμασία θα μας οδηγήσει στην αποδοχή της μηδενικής υπόθεσης ή την αποδοχή της, μέ κάποι δεδομένα όρια μέγιστης πιθανότητας λάθους (*στάθμη εμπιστοσύνης*). Όταν απορρίπτουμε την μηδενική υπόθεση, υιοθετούμε την *εναλλακτική υπόθεση* $H_a$. Η ταυτότητα των $H_0$ και $H_a$ εξαρτάται από την δοκιμασία. Γενικά ως μηδενική υπόθεση δεχόμασται οτι δεν υπάρχει σημαντική διαφορά και ως εναλλακτική οτι υπάρχει.
Μερικές κοινές εκδοχές είναι:

>$H_0$ οι διαφορές των δύο είναι τυχαίες, οπότε $H_a$ οι διαφορές δεν είναι τυχαίες\
>$H_0$ η τιμή ανοίκη στον πληθυσμό, $H_a$ η τιμή δεν ανοίκει στον πληθυσμό\
>$H_0:$ $\bar{x}= \mu$, $H_a: \bar{x}\ne\mu$\
>$H_0:\mu_A = \mu_B\;\; H_A: \mu_A\ne\mu_B$\
>$H_0:\sigma_A=\sigma_B,\;\;H_A:\sigma_A\ne\sigma_B$\
>$H_0:X_i\in A_i\;\; H_a:X_i\notin A_i$


>**Παρατήρηση:**
>Ισχύει πάντα:
>$$
P(H_0)+P(H_a) = 1
>$$

Σφάλμα **πρώτου είδους** έχουμε όταν απορρίπτουμε την μηδενική ενώ ισχύει και σφάλμα **δεύτερου είδους** έχουμε όταν απορρίπτουμε την εναλλάκτική υπόθεση ενώ αυτή ισχύει. Η *στάθμη εμπιστοσύνης* εκφράζει την ελάχιστη πιθανότητα σφάλματος πρώτου είδους. Είναι συνήθως 95%, σπανιότερα 90% (όταν οι απαιτήσεις είναι χαμηλές) ή 95% (όταν οι απαιτήσεις είναι υψηλές).

![σφάλματα και στάθμες εμπιστοσύνης]()

Το αποτέλεσμα μια δοκιμασίας γενικά αποδίδεται μέσω της τιμής $P$ που είναι η πιθανότητα σφάλματος πρώτου είδους. Όταν αυτή είναι **μεγαλύτερη** από την τιμή 1-στάθμη εμπιστοσύνης τότε η μηδενική ισχύει. Έστων $CL$ ή στάθμη εμπιστοσύνης. Τότε:

$$
P>1-CL \implies H_0\\
P<1-CL \implies H_a
$$

Διότι η τιμή $1-CL$ είναι η πιθανότητα σφάλματος πρώτου είδους. Για παράδειγμα αν $P=0.03\;\; και\;\; CL=90\%$

## Δοκιμασία T ή Student's Test ή T-Test

Μια από τις ποιό διαδεδομένες δοκιμασίες είναι η δοκιμασία Τ, η οποία έχει 2-3 παραλλαγές. Κατ' αρχάς η δοκιμασία βασίζεται στην εξής διαδικασία. Από μια κανονική κατανομή επιλέγονται Ν στοιχεία τυχαία, και τροφοδοτούνται σε μία συνάρτηση που δίνει μια τιμή τ. Αυτή η τιμή ανοίκει σε έναν νέο πληθυσμό (Τ). Η αρχική κανονική κατανομή απόδίδει τη διασπορά των πληθυσμιακών τυπικών αποκλίσεων ως προς την κεντρική τιμή (μ). Η παράγωγη κατανομή Τ αποδίδει τη διασπορά των τιμών ως προς την κεντρική κατανομή. Οι δε τιμές t είναι ο αριθμός των *δειγματικών τυπικών αποκλίσεων,s*. Η κατανομή Τ εμφανίζει ιδαίτερα έντονη διασπορά σε μικρές τιμές Ν. Υπάρχει έντονη αμφιβολία ως προς το κατά πόσο η τιμή s είναι πραγμτικά αξιόπιστη εκτιμήτρια της σ. Όσο η τιμή Ν αυξάνει, τόσο η κατανομή τείνει στην κανονική. Ο τύπος που χρησιμοποιούμε εξαρτάται από την ακριβής δοκιμασία:
$$
t_{exp} = \frac {|\mu -\bar{x}|\sqrt{N}}{s}\;\;\;Σύγκριση\; πραγματικής\; τιμής\; και\; μέσης\\
t_{exp}=\frac {|\bar {x_A} - \bar{x_B}|}{s_{A,B}\sqrt {\frac {1}{N_A}+{\frac {1}{N_B}}}}\;\; s_{A,B}=\frac {\sum_{i=1}^{N_A}{(\bar{x_A}-x_{i,A})^2} +\sum_{i=1}{N_B}{(\bar {x_B} - x_{i,B})^2} }{N_A + N_B-1}\;\; Σύγκριση\; δύο\; πειραματικών\; μέσω\; τιμών\\
t_{exp}=\frac {|\bar{d}|\sqrt{N}}{s_d}\;Δοκιμασία\; πειραματικών\; τιμών\; κατά\; ζεύγοι

$$